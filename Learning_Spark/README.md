# Learning Spark by Holden Karau etc from O'Reilly.

##[Programming with RDD]()

## Tips:
* quit pyspark: exit()
* quit spark-shell: ctrl + D

* Spark does not require Hadoop, it has support for storage systems implementing Hadoop APIs (including your local filesystem, AWS S3, Cassandra, Hive, HBase, etc).
